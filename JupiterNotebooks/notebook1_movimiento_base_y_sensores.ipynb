{"cells":[{"cell_type":"markdown","metadata":{"lang":"ja","id":"K8-Vd80mFqy_"},"source":["Notebooks adaptados y traducidos a partir de los tutoriales de código abierto \n","utilizados en las competencias virtuales de los últimos 2 años\n","Yamamoto, T., Terada, K., Ochiai, A. et al. Development of Human Support Robot as the research platform of a domestic mobile manipulator. Robomech J 6, 4 (2019). https://doi.org/10.1186/s40648-019-0132-3\n","\n","Por favor Consulte los originales en inglés y Japonés en https://github.com/hsr-project/hsrb_robocup_dspl_docker\n"]},{"cell_type":"markdown","metadata":{"id":"lyZ_MFCvFqzB"},"source":["Adaptado al españolp or Laboratorio BioRobótica UNAM\n","Oscar Fuentes\n"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"UJgGKZlrFqzD"},"source":["Para correr este notebook debe tenerse familiaridad con términos de ROS como tópicos, listeners, publishers, mensajes etc.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qqbva5-vFqzE"},"outputs":[],"source":["#ROS NOETIC UBUNTU 20 PYTHON3 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3I8GrZLsFqzG","colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"status":"error","timestamp":1660729358066,"user_tz":300,"elapsed":433,"user":{"displayName":"Juan Diego Zumba Arichavala","userId":"00194564589808201836"}},"outputId":"64e01b2a-bae6-4057-ca14-4ba4e525b634"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-4fa9fdf55ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstd_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeometry_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rospy'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import rospy\n","from std_msgs.msg import String\n","import time\n","import numpy as np\n","from geometry_msgs.msg import Twist\n"]},{"cell_type":"markdown","metadata":{"id":"zK_oMDvsFqzH"},"source":["Importamos Librerías pertinentes para el control de la base del robot. \n","Trabajamos a un alto nivel, es decir, confíamos que \"under the hood\" existe un control \n","que permite traducir velocidades en señales de control"]},{"cell_type":"markdown","metadata":{"id":"TrDIkDzKFqzH"},"source":["Atención especial al mensaje tipo Twist.\n","Un mensaje standar de ros dentro del paquete de mensajes geometry _msgs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"REe414XYFqzI","outputId":"2f3e3fa4-47de-4ed7-cda7-ec1d8e6614ec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660505319438,"user_tz":300,"elapsed":60,"user":{"displayName":"Salvador García Hérnandez","userId":"10122065872909803555"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: rosmsg: command not found\n"]}],"source":["! rosmsg info geometry_msgs/Twist"]},{"cell_type":"markdown","metadata":{"id":"NQeCF1N9FqzJ"},"source":["el mensaje consta de 2 vectores de 3 dimensiones, uno llamado angular y y otro llamado linear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTYjOsmWFqzL","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"error","timestamp":1660505319954,"user_tz":300,"elapsed":554,"user":{"displayName":"Salvador García Hérnandez","userId":"10122065872909803555"}},"outputId":"d35bd0e7-5667-4480-d38a-e767b77361ed"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-5d6dd9ca3155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'base_and_sensor'\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m### Conectamos/creamos un nodo llamado base and sensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase_vel_pub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPublisher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/hsrb/command_velocity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m## Declaramos un publisher que ha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m###de enviar mensajes tipo Twist al topico hsrb/command_velocity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'rospy' is not defined"]}],"source":["rospy.init_node('base_and_sensor')    ### Conectamos/creamos un nodo llamado base and sensor \n","base_vel_pub = rospy.Publisher('/hsrb/command_velocity', Twist, queue_size=10)## Declaramos un publisher que ha \n","###de enviar mensajes tipo Twist al topico hsrb/command_velocity\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nmz-Jd3QFqzM"},"outputs":[],"source":["\n","def move_base_vel(vx, vy, vw):\n","    twist = Twist()\n","    twist.linear.x = vx\n","    twist.linear.y = vy\n","    twist.angular.z = vw \n","    base_vel_pub.publish(twist)"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"K5hPsOpUFqzN"},"source":["Observe en el simulador y en RVIZ  al ingresar estos comandos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikOqlsc-FqzO"},"outputs":[],"source":["move_base_vel(0, 0.1, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVFcjYJjFqzO"},"outputs":[],"source":["twist.linear.x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGuRujKRFqzP"},"outputs":[],"source":["twist= Twist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Srt5caY0FqzP"},"outputs":[],"source":["move_base_vel(0.0, 1.1, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlHaKEjyFqzQ"},"outputs":[],"source":["move_base_vel(0 , 0, np.pi)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usjHJboYFqzQ"},"outputs":[],"source":["move_base_vel(1, 1, np.pi*.25)"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"Ft4UNu4wFqzR"},"source":["El robot HSR \"Takeshi\" tiene una base omnidireccional"]},{"cell_type":"markdown","metadata":{"id":"8oaXrz_MFqzS"},"source":["Prepárese para interrumir el KERNEL con el pequeño  botón de STOP ubicado arriba en el notebook"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"eyLlyjBrFqzS"},"source":["Oops! The robot bumped into the wall. Press the ■ button above to stop our code.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"q53usTB3FqzT"},"outputs":[],"source":["#puede mantenerse la velocidad deseada por ejemplo\n","while True:\n","    move_base_vel(1, 0, 0)"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"jT9wEqtLFqzT"},"source":["Ahora vamos a correr por un intervalo de tiempo definido la celda siguiente mantendrá una velocidad de 0.5m/s por 3 segundos:"]},{"cell_type":"code","execution_count":null,"metadata":{"lang":"ja","id":"MkLJt5VEFqzT"},"outputs":[],"source":["start_time = rospy.Time.now().to_sec()  \n","while rospy.Time.now().to_sec() - start_time < 3: \n","    move_base_vel(-0.5, 0, 0)"]},{"cell_type":"markdown","metadata":{"id":"weToVHcpFqzU"},"source":["EJERCICIO EN CLASE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0joTh5ZFqzU"},"outputs":[],"source":["def move_base(x,y,yaw,timeout=5):\n","    start_time = rospy.Time.now().to_sec()\n","    while rospy.Time.now().to_sec() - start_time < timeout:  \n","        move_base_vel(x, y, yaw)"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"-uTduBqRFqzU"},"source":["TAREA:"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"o0gTQXFaFqzV"},"source":["Escriba un pequeño código que permita al robot volver al punto de partida de este tutorial, después de rodear el pequeño rover"]},{"cell_type":"markdown","metadata":{"id":"qXe7tM5qFqzV"},"source":["Ahondaremos en el uso de tf en ros en sesiones futuras, por ahora utilicemos esta simple función para obtener de forma objetiva la posicionde inicio y final\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_W_vRjaFqzV"},"outputs":[],"source":["import tf2_ros\n","tfBuffer = tf2_ros.Buffer()\n","listener = tf2_ros.TransformListener(tfBuffer)\n","def get_coords ():\n","    trans = tfBuffer.lookup_transform('map', 'base_link', rospy.Time())\n","    return trans\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMZIZtowFqzV"},"outputs":[],"source":["coords_start= get_coords()\n","move_base(0,0,.12*np.pi,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tugoWftkFqzW"},"outputs":[],"source":["move_base(0.05,0,0,0.5)\n","move_base(0.3,0,0,0.5)\n","move_base(0.4,0,0,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkXqovK1FqzW"},"outputs":[],"source":["move_base(0,0,.12*np.pi,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZic0x55FqzW"},"outputs":[],"source":["move_base(0.05,0,0,0.5)\n","move_base(0.3,0,0,0.5)\n","move_base(0.4,0,0,0.5)\n","move_base(1,0,0,2.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EICYTA74FqzX"},"outputs":[],"source":["move_base(0,0,.12*np.pi,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CcT-aFd3FqzX"},"outputs":[],"source":["move_base(0.05,0,0,0.5)\n","move_base(0.3,0,0,0.5)\n","move_base(0.4,0,0,0.5)\n","move_base(1,0,0,6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQVUXK4uFqzY"},"outputs":[],"source":["move_base(0,0,.12*np.pi,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9770-TF3FqzY"},"outputs":[],"source":["move_base(0.05,0,0,0.5)\n","move_base(0.3,0,0,0.5)\n","move_base(0.4,0,0,0.5)\n","move_base(1,0,0,6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"laZ4RgnoFqzY"},"outputs":[],"source":["move_base(0,0,.12*np.pi,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUl5JNUUFqzZ"},"outputs":[],"source":["move_base(0.05,0,0,0.5)\n","move_base(0.3,0,0,0.5)\n","move_base(0.4,0,0,0.5)\n","move_base(1,0,0,6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kbuAHkBqFqzZ"},"outputs":[],"source":["coords_end= get_coords()\n","coords_start.transform.translation,coords_end.transform.translation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nrRX7ZqrFqzZ"},"outputs":[],"source":["print(coords_start.transform.translation,coords_end.transform.translation)"]},{"cell_type":"markdown","metadata":{"id":"bho4HUBMFqza"},"source":["Sensores:\n","Si bien el HSR cuenta con muchos más sensores, (incluída la versión simulada) , por ahora nos concentramos en 2 sensores concretamente, que permiten extraer mucha información valiosa. \n","\n","Primero  EL LIDAR: Un conjunto de distancias distribuidas en un arco 270grados frente al robot\n","y luego camara rgbd xtion. Que nos da información en una imagen rgb común, y la nube de puntos relacionada. "]},{"cell_type":"markdown","metadata":{"lang":"en","id":"3V-gIRYqFqza"},"source":["# Capturing sensor information\n","In the previous section, we controlled the movement of the robot using our prior knowledge about the environment. In this section, we will use sensors to acquire environmental information to move the robot.\n","\n","We can use the following sensors installed in HSR:\n","\n","- Laser scanner: Two-dimensional measurement of distance to obstacles\n","\n","- RGB-D camera: A camera that can measure color information (RGB) + depth information (Depth)\n","\n","- IMU: Measures acceleration, angular acceleration, and magnetic force\n","\n","- Encoders: Measures each joint angle of the robot"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"jgdUCCcZFqzb"},"source":["## センサ情報の確認方法"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"4sy9HmMQFqzc"},"source":["## How to visualize sensor information"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"GWu08Re5Fqzc"},"source":["rvizを使ってセンサ情報を視覚的に確認してみましょう。\n","\n","まずは、以下のコマンドを実行してrvizを起動します。"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"OXSWCaJbFqzd"},"source":["Let's check the sensor information visually using RViz.\n","\n","First, launch RViz by executing the following command:\n","\n","Primero, analicemos la información de los sensores usando RVIZ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bea49RYDFqzd"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asqEBBUEFqzd"},"outputs":[],"source":["%%script bash --bg\n","rviz -d data/2_base_and_sensor.rviz > /dev/null 2>&1"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"eSX8R5FkFqze"},"source":["En la ventana displays de RVIZ buscar y desplegar \n","\n","- RobotModel: Representación del estado del robot\n","\n","\n","- LaserScan: Sensor LIDAR \n","\n","\n","- Image: imagen  rgb\n","\n","\n","- PointCloud2: Nube de Puntos"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"k33hM95kFqze"},"source":["Please check the data you are interested in using the \"Displays\" panel on the left side of the screen. The meaning of each item is as follows:\n","\n","- RobotModel: Robot CG model that reflects robot position estimation and joint angles.\n","\n","- LaserScan: Two-dimensional distance to obstacles measured by the laser scanner.\n","\n","- Image: Image from the RGB-D camera mounted on the head.\n","\n","- PointCloud2: Point cloud information of the environment generated from the RGB-D camera."]},{"cell_type":"markdown","metadata":{"id":"S8TWvQACFqzf"},"source":["Ejemplo de una clase que permite leer la información (tipo LaserScan) del topico '/hsrb/base_scan'"]},{"cell_type":"code","execution_count":null,"metadata":{"lang":"ja","id":"KsR_iBFEFqzf"},"outputs":[],"source":["from sensor_msgs.msg import LaserScan\n","\n","class Laser():\n","    u\"\"\"Class that handles laser information\"\"\"\n","\n","    def __init__(self):\n","        # Register the _laser_cb method as a callback to the laser scan topic events\n","        self._laser_sub = rospy.Subscriber ('/hsrb/base_scan',\n","                                           LaserScan, self._laser_cb)\n","        self._scan_data = None\n","\n","    def _laser_cb (self, msg):\n","        # Laser scan callback function\n","        self._scan_data = msg\n","\n","    def get_data(self):\n","        u\"\"\"Function to get the laser value\"\"\"\n","        return self._scan_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TE3sPPddFqzg"},"outputs":[],"source":["laser = Laser()  #instanciamos una clase "]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"kO0gPMeVFqzg"},"source":["以下を実行することで、データを取得することができます。取得されたセンサ値を、`scan_data`変数に格納しています。"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"yryv-uCjFqzg"},"source":["\n","Llamando en método `get_data()` almacenamos la información del sensor en la variable `scan_data`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"o6ZRn-d-Fqzh"},"outputs":[],"source":["scan_data = laser.get_data()"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"dJZDwn0jFqzh"},"source":["`scan_data`変数に格納されたセンサ値の中身を見てみましょう。"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"r9psJudBFqzi"},"source":["Analicemos la variable `scan_data` :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PlGsp5VnFqzi"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"wNhkMgoRFqzj"},"outputs":[],"source":["scan_data"]},{"cell_type":"code","execution_count":null,"metadata":{"lang":"ja","id":"snSD1icEFqzj"},"outputs":[],"source":["##Ejemplo de como acceder a los datos del mensaje\n","scan_data.angle_max / np.pi * 180  # math.pi = π"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"fhIxxNzYFqzk"},"source":["レーザスキャナのデータ本体は、`ranges`という名前の配列に格納されており、配列の長さは721のようです。"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"tt3He3eIFqzk"},"source":["The actual laser scanner data is stored in the array named `ranges`, and the length of the array seems to be 721:"]},{"cell_type":"markdown","metadata":{"id":"k9reM-hzFqzl"},"source":["La información del scanner se encuentra en el arreglo llamado `ranges`, su longitud es de  721:"]},{"cell_type":"code","execution_count":null,"metadata":{"lang":"ja","id":"rOZEH6FdFqzl"},"outputs":[],"source":["# データの配列の長さを取得 Get length of the array\n","len(scan_data.ranges)"]},{"cell_type":"markdown","metadata":{"lang":"ja","id":"APfZhYeEFqzl"},"source":["スキャン範囲（-120度から120度）上の各観測点がデータ化されているので、配列の真ん中（=361番目）の要素が「ロボット正面から壁までの距離」を表します。\n","\n","センサ値の単位はメートルです。"]},{"cell_type":"markdown","metadata":{"lang":"en","id":"6HW578n-Fqzl"},"source":["Since each observation point on the scan range (-120 degrees to 120 degrees) is digitized from left to right, the element in the middle of the array (= 361th) represents the \"distance from the front of the robot to the wall\".\n","\n","The unit of sensor value is meters."]},{"cell_type":"markdown","metadata":{"lang":"en","id":"QOziCWczFqzm"},"source":["Ya que cada observación está dividida en un arco (-120 degrees to 120 degrees) el elemento en el centro del arreglo (= 361)representa la distancia frente al robot en metros\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"lang":"ja","id":"7wu8MZwZFqzm"},"outputs":[],"source":["# 361番目のデータにアクセス Access the 361th data\n","scan_data.ranges[360]"]},{"cell_type":"markdown","metadata":{"id":"jZC5c59XFqzm"},"source":["Tarea  utililce la información del sensores para mejorar el código que propuso en la tarea anterior. Como evitar chocar con la pared? Todos los obstáculos son visibles al robot?\n","A falta de mapa, como recordar la posición inicial"]},{"cell_type":"markdown","metadata":{"id":"6x3WkFieFqzm"},"source":["¡Buena Suerte!"]},{"cell_type":"markdown","metadata":{"id":"E2FWzlwWFqzn"},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4uSkQA7Fqzn"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd3nqY9cFqzn"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUMshBBuFqzo"},"outputs":[],"source":["trans = tfBuffer.lookup_transform('map', 'base_link', rospy.Time())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"259OvzHFFqzo"},"outputs":[],"source":["def set_waypoint ():\n","    trans = tfBuffer.lookup_transform('map', 'base_link', rospy.Time())\n","    return trans\n","\n","trans_goal= set_waypoint()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6C-2LS00Fqzo"},"outputs":[],"source":["tans_start_point =set_waypoint()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtfIlz2TFqzp"},"outputs":[],"source":["tans_start_point"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"nbTranslate":{"displayLangs":["ja","en"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"ja","targetLang":"en","useGoogleTranslate":true},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"notebook1_movimiento_base_y_sensores.ipynb","provenance":[],"collapsed_sections":["jgdUCCcZFqzb"]}},"nbformat":4,"nbformat_minor":0}